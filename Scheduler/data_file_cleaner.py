""" This script is used to clean up data file generated by the atlin project.
"""
import time
from datetime import datetime
import os
import shutil
import logging
from logging.handlers import RotatingFileHandler
from requests.exceptions import Timeout, HTTPError, RequestException

from pathlib import Path
import sys

BASE_DIR = Path(__file__).resolve().parent.parent.as_posix()
sys.path.insert(0, BASE_DIR)

import Config as config
from atlin_api.atlin_api import Atlin, JobStatus

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

def initialize_logging():
    """_summary_

    Returns:
        _type_: _description_
    """
    log_file_path = os.path.join(config.LOGGER_DIR_PATH,'file_cleaner_log_')

    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s %(levelname)s %(filename)s %(funcName)s(%(lineno)d) %(message)s',
        handlers=[
            RotatingFileHandler(
                f"{log_file_path}{time.strftime('%y%m%d_%H%M')}.log",
                mode='a',
                maxBytes=5*1024*1024,
                backupCount=2,
                encoding=None,
                delay=0,
            ),
        ])

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

def get_successful_jobs() -> list:
    """ get all the jobs with status "successful" from the db

    Raises:
        e: error raised from atlin back end api

    Returns:
        list: return a list of api responses
    """
    # start a session with the backend API
    atlin_session = Atlin(config.ATLIN_API_ADDRESS)

    response = None

    # request all the "success"
    try:
        response = atlin_session.job_get(job_status=[JobStatus.success])
    except Exception as e:
        raise e

    return response.json()

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

def time_since_completed(job : dict) -> float:
    """calculates the time in seconds since the job was completed

    Args:
        job (dict): dictionary representation of db row

    Returns:
        float: time in seconds since job was completed sucessfully
    """

    current_date = datetime.now()

    # we only care about the year-month-day part
    completed_date = job['complete_date'].split('T')[0]
    date_completed = datetime.strptime(completed_date, '%Y-%m-%d')

    return (current_date-date_completed).total_seconds()

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

def passed_delete_date(delta_time : float) -> bool:
    """check if elpased time is greater than the amount of time before 
    needing to delete the file

    Args:
        delta_time (float): elapsed time since deletion

    Returns:
        bool: true if elapsed time greater than keep time
    """

    sec_in_day = 60*60*24

    return delta_time > config.DATA_FILE_KEEP_N_DAYS*sec_in_day

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

def set_job_status( job_uid : str,
                    job_status : JobStatus) -> None:
    """ Sets the status of a job in the db

    Args: Sets status of job with id 'job_uid' to 'status
        job_uid (str): uid of job in data base
        job_status (JobStatus): change job status to

    Raises:
        e: exception raised by atlin api accessing backend
    """
    # start a session with the backend API
    atlin_session = Atlin(config.ATLIN_API_ADDRESS)

    try:
        atlin_session.job_set_status(job_uid, job_status)
    except Exception as e:
        raise e

    return

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

def delete_output_data(output_path : str) -> None:
    """attempts to delete data files generated by a job

    Args:
        output_path (str): path to output directory

    Raises:
        e: exception raised trying to access the output directory path

    """

    try:
        if os.path.exists(output_path):
            shutil.rmtree(output_path)
    except OSError as e:
        raise e

    return

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

def delete_job(job : dict) -> None:
    """Handles the detection of a job

    Args:
        job (dict): dictionary representation of db row
    """
    try:
        delete_output_data(job['output_path'])
        set_job_status(job['job_uid'], JobStatus.deleted)
    except Exception as e:
        raise e

    return

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

def main():
    """Removes data files if they are passed expiration date and updates
    the db accordingly
    """

    initialize_logging()

    done_job_list = get_successful_jobs()
    logging.info('Found %d successful job(s)', len(done_job_list))

    for job in done_job_list:

        delta_time = time_since_completed(job)
        if passed_delete_date(delta_time):
            try:
                delete_job(job)
                logging.info('Delete job %s', job['job_uid'])
            except (ConnectionError, Timeout) as e:
                logging.error('A connection error or timeout occurred: %s', e)
            except HTTPError as e:
                logging.error('HTTP Error: %s', e)
            except RequestException as e:
                logging.error('An error occurred: %s',e)
            except OSError as e:
                logging.error('Unable to delete data files: %s', e)

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

if __name__ == '__main__':
    main()
